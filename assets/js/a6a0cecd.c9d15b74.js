"use strict";(self.webpackChunksite=self.webpackChunksite||[]).push([[368],{8766:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>a,contentTitle:()=>r,default:()=>h,frontMatter:()=>i,metadata:()=>l,toc:()=>d});var s=n(5893),o=n(1151);const i={sidebar_position:1},r="Test \ud83e\uddea",l={id:"commands/test",title:"Test \ud83e\uddea",description:"Run tests in a Dart or Flutter project with very_good test.",source:"@site/docs/commands/test.md",sourceDirName:"commands",slug:"/commands/test",permalink:"/docs/commands/test",draft:!1,unlisted:!1,editUrl:"https://github.com/verygoodopensource/very_good_cli/tree/main/site/docs/commands/test.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Commands",permalink:"/docs/category/commands"},next:{title:"Get Packages \ud83d\udce6",permalink:"/docs/commands/get_pkgs"}},a={},d=[{value:"Usage",id:"usage",level:2},{value:"Passing Flutter specific arguments",id:"passing-flutter-specific-arguments",level:3},{value:"Tests without pub install",id:"tests-without-pub-install",level:3},{value:"Golden tests",id:"golden-tests",level:3}];function c(e){const t={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",mdxAdmonitionTitle:"mdxAdmonitionTitle",p:"p",pre:"pre",strong:"strong",...(0,o.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"test-",children:"Test \ud83e\uddea"})}),"\n",(0,s.jsxs)(t.p,{children:["Run tests in a Dart or Flutter project with ",(0,s.jsx)(t.code,{children:"very_good test"}),"."]}),"\n",(0,s.jsxs)(t.p,{children:["By default, this command will optimize your tests to run more efficiently by grouping them into a single entrypoint (see ",(0,s.jsx)(t.a,{href:"https://github.com/flutter/flutter/issues/90225",children:"this issue"}),")."]}),"\n",(0,s.jsx)(t.h2,{id:"usage",children:"Usage"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-sh",children:'very_good test [arguments]\n-h, --help                            Print this usage information.\n    --coverage                        Whether to collect coverage information.\n-r, --recursive                       Run tests recursively for all nested packages.\n    --[no-]optimization               Whether to apply optimizations for test performance.\n                                      (defaults to on)\n-j, --concurrency                     The number of concurrent test suites run.\n                                      (defaults to "4")\n-t, --tags                            Run only tests associated with the specified tags.\n    --exclude-coverage                A glob which will be used to exclude files that match from the coverage.\n-x, --exclude-tags                    Run only tests that do not have the specified tags.\n    --min-coverage                    Whether to enforce a minimum coverage percentage.\n    --test-randomize-ordering-seed    The seed to randomize the execution order of test cases within test files.\n    --update-goldens                  Whether "matchesGoldenFile()" calls within your test methods should update the golden files.\n    --force-ansi                      Whether to force ansi output. If not specified, it will maintain the default behavior based on stdout and stderr.\n    --dart-define=<foo=bar>           Additional key-value pairs that will be available as constants from the String.fromEnvironment, bool.fromEnvironment, int.fromEnvironment, and double.fromEnvironment constructors. Multiple defines can be passed by repeating "--dart-define" multiple times.\n\nRun "very_good help" to see global options.\n'})}),"\n",(0,s.jsx)(t.h3,{id:"passing-flutter-specific-arguments",children:"Passing Flutter specific arguments"}),"\n",(0,s.jsxs)(t.p,{children:["The ",(0,s.jsx)(t.code,{children:"flutter test"})," command exposes more arguments than those available through ",(0,s.jsx)(t.code,{children:"very_good test"}),". Despite this, you can use the argument terminator ",(0,s.jsx)(t.code,{children:"--"})," to signify the end of ",(0,s.jsx)(t.code,{children:"very_good test"})," command options and the beginning of ",(0,s.jsx)(t.code,{children:"flutter test"})," command options; making all ",(0,s.jsx)(t.code,{children:"flutter test"})," arguments available!"]}),"\n",(0,s.jsxs)(t.p,{children:["For example, if you wish to run ",(0,s.jsx)(t.code,{children:"flutter test --no-track-widget-creation"})," you can simply use ",(0,s.jsx)(t.code,{children:"very_good test -- --no-track-widget-creation"}),"."]}),"\n",(0,s.jsx)(t.h3,{id:"tests-without-pub-install",children:"Tests without pub install"}),"\n",(0,s.jsxs)(t.p,{children:["Unlike ",(0,s.jsx)(t.code,{children:"flutter test"}),", ",(0,s.jsx)(t.code,{children:"very_good test"})," will always run your tests without installing the projects dependencies (i.e. ",(0,s.jsx)(t.code,{children:"--no-pub"})," flag)."]}),"\n",(0,s.jsx)(t.p,{children:"This is an optimization done by the CLI because dependency installation is usually run once after cloning the repository. Conversely, running tests locally is usually done many times and it's often unnecessary to re-install dependencies prior to each test run."}),"\n",(0,s.jsxs)(t.p,{children:["If you need to install dependencies before running the tests with ",(0,s.jsx)(t.code,{children:"very_good_cli"}),", be sure to run ",(0,s.jsx)(t.code,{children:"very_good packages get"})," first."]}),"\n",(0,s.jsx)(t.h3,{id:"golden-tests",children:"Golden tests"}),"\n",(0,s.jsxs)(t.p,{children:['Golden tests are tests that compare the output of a test to a "golden" file. If the output of the test does not match the golden file, the test will fail. These usually invoke the ',(0,s.jsx)(t.a,{href:"https://api.flutter.dev/flutter/flutter_test/matchesGoldenFile.html",children:(0,s.jsx)(t.code,{children:"matchesGoldenFile"})})," matcher, which supports specifying a ",(0,s.jsx)(t.a,{href:"https://api.flutter.dev/flutter/flutter_test/GoldenFileComparator-class.html",children:(0,s.jsx)(t.code,{children:"GoldenFileComparator"})})," to customize the comparison by setting the top-level property ",(0,s.jsx)(t.a,{href:"https://api.flutter.dev/flutter/flutter_test/goldenFileComparator.html",children:(0,s.jsx)(t.code,{children:"goldenFileComparator"})}),", for example to accept a certain amount of difference."]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.a,{href:"https://cli.vgv.dev/",children:"Very Good CLI"})," supports golden tests out of the box, with and without a custom ",(0,s.jsx)(t.a,{href:"https://api.flutter.dev/flutter/flutter_test/goldenFileComparator.html",children:(0,s.jsx)(t.code,{children:"goldenFileComparator"})}),". This means that ",(0,s.jsx)(t.strong,{children:"no change is required"})," to your test code to run them with ",(0,s.jsx)(t.code,{children:"very_good test"}),"."]}),"\n",(0,s.jsx)(t.admonition,{type:"info",children:(0,s.jsxs)(t.mdxAdmonitionTitle,{children:["For an example on specifying a custom ",(0,s.jsx)(t.a,{href:"https://api.flutter.dev/flutter/flutter_test/GoldenFileComparator-class.html",children:(0,s.jsx)(t.code,{children:"GoldenFileComparator"})})," that accepts a certain amount of difference (toleration threshold), refer to the ",(0,s.jsxs)(t.a,{href:"https://api.flutter.dev/flutter/flutter_test/goldenFileComparator.html",children:[(0,s.jsx)(t.code,{children:"goldenFileComparator"})," Flutter documentation"]}),". :::"]})})]})}function h(e={}){const{wrapper:t}={...(0,o.a)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},1151:(e,t,n)=>{n.d(t,{Z:()=>l,a:()=>r});var s=n(7294);const o={},i=s.createContext(o);function r(e){const t=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),s.createElement(i.Provider,{value:t},e.children)}}}]);